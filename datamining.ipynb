{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f5ddaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PART (a): STANDARDIZATION & REGRESSION \n",
      "Standardized Data:\n",
      "     Age  Tickets   Time  Spend\n",
      "0 -0.661    0.463  0.378  0.795\n",
      "1  0.763   -0.926 -0.995 -1.036\n",
      "2 -1.373    0.000  1.065 -0.015\n",
      "3  0.229    1.389  1.310  1.569\n",
      "4  1.475   -1.389 -1.191 -1.212\n",
      "5 -0.839    0.926  0.182  0.372\n",
      "6  0.407   -0.463 -0.750 -0.473\n",
      "\n",
      "Standardized Coefficients:\n",
      "β₀ (Intercept): -0.000\n",
      "β₁ (Age): 0.212\n",
      "β₂ (Tickets): 0.776\n",
      "β₃ (Time): 0.370\n",
      "\n",
      "Original Scale Coefficients:\n",
      "Intercept: -171.332\n",
      "Age: 5.366\n",
      "Tickets: 51.016\n",
      "Time: 2.580\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data\n",
    "data = {\n",
    "    'Age': [23, 31, 19, 28, 35, 22, 29],\n",
    "    'Tickets': [5, 2, 4, 7, 1, 6, 3],\n",
    "    'Time': [43, 15, 57, 62, 11, 39, 20],\n",
    "    'Spend': [380, 120, 265, 490, 95, 320, 200]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Part (a): Standardization & Regression\n",
    "print(\"PART (a): STANDARDIZATION & REGRESSION \")\n",
    "\n",
    "# Standardize\n",
    "df_std = (df - df.mean()) / df.std()\n",
    "print(\"Standardized Data:\")\n",
    "print(df_std.round(3))\n",
    "\n",
    "# Fit regression\n",
    "X = np.column_stack([np.ones(len(df)), df_std[['Age', 'Tickets', 'Time']].values])\n",
    "y = df_std['Spend'].values.reshape(-1, 1)\n",
    "beta_std = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "\n",
    "print(\"\\nStandardized Coefficients:\")\n",
    "print(f\"β₀ (Intercept): {beta_std[0][0]:.3f}\")\n",
    "print(f\"β₁ (Age): {beta_std[1][0]:.3f}\")\n",
    "print(f\"β₂ (Tickets): {beta_std[2][0]:.3f}\")\n",
    "print(f\"β₃ (Time): {beta_std[3][0]:.3f}\")\n",
    "\n",
    "# Convert to original scale\n",
    "means = df.mean()\n",
    "stds = df.std()\n",
    "beta_original = beta_std.flatten().copy()\n",
    "beta_original[1:] = beta_original[1:] * (stds['Spend'] / stds[['Age', 'Tickets', 'Time']].values)\n",
    "beta_original[0] = means['Spend'] - np.sum(beta_original[1:] * means[['Age', 'Tickets', 'Time']].values)\n",
    "\n",
    "print(\"\\nOriginal Scale Coefficients:\")\n",
    "print(f\"Intercept: {beta_original[0]:.3f}\")\n",
    "print(f\"Age: {beta_original[1]:.3f}\")\n",
    "print(f\"Tickets: {beta_original[2]:.3f}\")\n",
    "print(f\"Time: {beta_original[3]:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e463c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " PART (c): PREDICTION \n",
      "Predicted Spend for Age=30, Tickets=4, Time=50: 322.74\n",
      "\n",
      " ASSOCIATION METRICS \n",
      "Rule: Time > 40 → Spend > 300\n",
      "Support(Time>40) = 0.429\n",
      "Support(Spend>300) = 0.429\n",
      "Support(Both) = 0.286\n",
      "Confidence = 0.667 (66.7%)\n",
      "Lift = 1.556\n",
      "\n",
      " DAYTYPE CLASSIFICATION \n",
      "Simple Rule: IF Time>50 OR Tickets>5 THEN Weekend ELSE Weekday\n",
      "   Age  Tickets  Time  Spend  DayType\n",
      "0   23        5    43    380  Weekday\n",
      "1   31        2    15    120  Weekday\n",
      "2   19        4    57    265  Weekend\n",
      "3   28        7    62    490  Weekend\n",
      "4   35        1    11     95  Weekday\n",
      "5   22        6    39    320  Weekend\n",
      "6   29        3    20    200  Weekday\n"
     ]
    }
   ],
   "source": [
    "#Part (c): Prediction\n",
    "print(\"\\n PART (c): PREDICTION \")\n",
    "new_age, new_tickets, new_time = 30, 4, 50\n",
    "spend_pred = (beta_original[0] + \n",
    "            beta_original[1]*new_age + \n",
    "            beta_original[2]*new_tickets + \n",
    "            beta_original[3]*new_time)\n",
    "print(f\"Predicted Spend for Age={new_age}, Tickets={new_tickets}, Time={new_time}: {spend_pred:.2f}\")\n",
    "\n",
    "# Association metrics\n",
    "print(\"\\n ASSOCIATION METRICS \")\n",
    "time_gt_40 = df['Time'] > 40\n",
    "spend_gt_300 = df['Spend'] > 300\n",
    "support_time = time_gt_40.mean()\n",
    "support_spend = spend_gt_300.mean()\n",
    "support_both = (time_gt_40 & spend_gt_300).mean()\n",
    "\n",
    "confidence = support_both / support_time\n",
    "lift = support_both / (support_time * support_spend)\n",
    "\n",
    "print(f\"Rule: Time > 40 → Spend > 300\")\n",
    "print(f\"Support(Time>40) = {support_time:.3f}\")\n",
    "print(f\"Support(Spend>300) = {support_spend:.3f}\")\n",
    "print(f\"Support(Both) = {support_both:.3f}\")\n",
    "print(f\"Confidence = {confidence:.3f} ({confidence*100:.1f}%)\")\n",
    "print(f\"Lift = {lift:.3f}\")\n",
    "\n",
    "# Classification rule\n",
    "print(\"\\n DAYTYPE CLASSIFICATION \")\n",
    "df['DayType'] = np.where(df['Time'] > 50, 'Weekend',\n",
    "                np.where(df['Tickets'] > 5, 'Weekend', 'Weekday'))\n",
    "print(\"Simple Rule: IF Time>50 OR Tickets>5 THEN Weekend ELSE Weekday\")\n",
    "print(df[['Age', 'Tickets', 'Time', 'Spend', 'DayType']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f710bec",
   "metadata": {},
   "source": [
    "### QUESTION TWO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a2dbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION 2: SALES & CUSTOMER SEGMENTATION\n",
      "\n",
      "(a) MULTIDIMENSIONAL CUBE\n",
      "Monthly Sales Data (KSh '000):\n",
      "        Jan  Feb  Mar\n",
      "Region               \n",
      "North   120  135  128\n",
      "South    95  110  102\n",
      "East    140  150  145\n",
      "\n",
      "Feb sales for East: 150 KSh '000\n"
     ]
    }
   ],
   "source": [
    "print(\"QUESTION 2: SALES & CUSTOMER SEGMENTATION\")\n",
    "\n",
    "# Part (a): Multidimensional Cube\n",
    "print(\"\\n(a) MULTIDIMENSIONAL CUBE\")\n",
    "\n",
    "sales_data = {\n",
    "   'Region': ['North', 'South', 'East'],\n",
    "   'Jan': [120, 95, 140],\n",
    "   'Feb': [135, 110, 150],\n",
    "   'Mar': [128, 102, 145]\n",
    "}\n",
    "sales_df = pd.DataFrame(sales_data).set_index('Region')\n",
    "print(\"Monthly Sales Data (KSh '000):\")\n",
    "print(sales_df)\n",
    "print(f\"\\nFeb sales for East: {sales_df.loc['East', 'Feb']} KSh '000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769600b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(b) DATA NORMALIZATION\n",
      "Customer Segmentation Data (Original):\n",
      "   Age  Income  PurchaseFrequency\n",
      "0   25      50                  5\n",
      "1   32      70                  3\n",
      "2   22      45                  6\n",
      "3   28      60                  4\n",
      "\n",
      "Min-Max Normalized Data:\n",
      "   Age  Income  PurchaseFrequency\n",
      "0  0.3     0.2              0.667\n",
      "1  1.0     1.0              0.000\n",
      "2  0.0     0.0              1.000\n",
      "3  0.6     0.6              0.333\n"
     ]
    }
   ],
   "source": [
    "# Part (b): Normalization\n",
    "print(\"\\n\\n(b) DATA NORMALIZATION\")\n",
    "\n",
    "segmentation_data = {\n",
    "    'Age': [25, 32, 22, 28],\n",
    "    'Income': [50, 70, 45, 60],\n",
    "    'PurchaseFrequency': [5, 3, 6, 4]\n",
    "}\n",
    "seg_df = pd.DataFrame(segmentation_data)\n",
    "\n",
    "# Min-Max Normalization\n",
    "def min_max_normalize(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "seg_norm = min_max_normalize(seg_df)\n",
    "print(\"Customer Segmentation Data (Original):\")\n",
    "print(seg_df)\n",
    "print(\"\\nMin-Max Normalized Data:\")\n",
    "print(seg_norm.round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "375a5f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(c) K-MEANS CLUSTERING (k=2)\n",
      "Cluster Assignments:\n",
      "   Age  Income  PurchaseFrequency  Cluster\n",
      "0   25      50                  5        1\n",
      "1   32      70                  3        0\n",
      "2   22      45                  6        1\n",
      "3   28      60                  4        0\n",
      "\n",
      "Cluster Centroids:\n",
      "   Age_norm  Income_norm  Freq_norm\n",
      "0      0.80          0.8   0.166667\n",
      "1      0.15          0.1   0.833333\n"
     ]
    }
   ],
   "source": [
    "# Part (c): Clustering\n",
    "print(\"\\n\\n(c) K-MEANS CLUSTERING (k=2)\")\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Apply K-means\n",
    "kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "seg_df['Cluster'] = kmeans.fit_predict(seg_norm)\n",
    "\n",
    "print(\"Cluster Assignments:\")\n",
    "print(seg_df[['Age', 'Income', 'PurchaseFrequency', 'Cluster']])\n",
    "print(f\"\\nCluster Centroids:\")\n",
    "print(pd.DataFrame(kmeans.cluster_centers_, \n",
    "                columns=['Age_norm', 'Income_norm', 'Freq_norm']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "782257c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Actual Centroids (Original Scale):\n",
      "Cluster 0: [30.  65.   3.5]\n",
      "Cluster 1: [23.5 47.5  5.5]\n"
     ]
    }
   ],
   "source": [
    "# Calculate actual centroids in original scale\n",
    "cluster_0 = seg_df[seg_df['Cluster'] == 0][['Age', 'Income', 'PurchaseFrequency']]\n",
    "cluster_1 = seg_df[seg_df['Cluster'] == 1][['Age', 'Income', 'PurchaseFrequency']]\n",
    "\n",
    "print(\"\\nActual Centroids (Original Scale):\")\n",
    "print(\"Cluster 0:\", cluster_0.mean().round(2).values)\n",
    "print(\"Cluster 1:\", cluster_1.mean().round(2).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b35db4c",
   "metadata": {},
   "source": [
    "\n",
    "# Part (d): Cross-Validation & Ensemble\n",
    "\n",
    "1. Leave-One-Out (LOO):\n",
    "   - Train on n-1 samples, test on 1, repeat n times\n",
    "   - Low bias but high variance\n",
    "   - Computationally expensive for large n\n",
    "\n",
    "2. k-Fold Cross-Validation:\n",
    "   - Split data into k equal folds\n",
    "   - Train on k-1 folds, test on remaining fold\n",
    "   - Better bias-variance tradeoff\n",
    "   - Typically k=5 or k=10\n",
    "\n",
    "Ensemble Methods Improve Accuracy By:\n",
    "1. Reducing variance (Bagging): Average multiple models\n",
    "2. Reducing bias (Boosting): Sequentially correct errors  \n",
    "3. Increasing diversity: Different models capture different patterns\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
